# LLM-Bias

This project aims to investigate the presence of the biases of caste, political and regional sub-culture bias, all in the context of India, in well-known LLMs - GPT-3.5, GPT-4, Gemini 1.5-pro and Llama-2. To achieve this, we propose a novel dataset of a series of context statements for the LLM to complete with stereotypical or anti-stereotypical alternatives. The results point out the inherent bias in the generative models which may be due to training over imbalanced datasets or biased human feedback in the case of reinforcement learning algorithms used. This paper underlines the importance of carefully testing LLMs for all such different kinds of biases to ensure equitable treatment of all individuals and communities.


![llm-fig-1](https://github.com/jhanvee-khola/LLM-Bias/assets/77978729/0de58469-78d6-4c4b-a863-2510787932aa)
Example of sentence completion tasks given to the LLMs for evaluation
